\documentclass[a4paper,twoside,11pt]{report} %openright
\usepackage{lipsum}
\usepackage{pgfgantt}
\usepackage{adjustbox}

\input{setup/statics.tex}
\input{setup/preamble.tex}
\input{setup/settings.tex}

\begin{document}

\pagenumbering{roman}
\input{frontmatter/frontpage.tex}
\pagecolor{white}
\newgeometry{top=2.81cm, bottom=2.75cm, outer=2.5cm, inner=3.5cm}
\pagestyle{empty}
\pagestyle{main}

\section*{Abstract}
Supply-chain attacks have been an ongoing issue in the software industry,
resulting in large financial damages in recent years. These attacks target a
victim’s supplier, exploiting the fact that the victim software depends on
software provided by the supplier. As modern software consists of thousands of
dependencies, it is challenging for developers to audit all dependencies—and
particularly so for dependencies nested deeply in the dependency chain.
Automated detection of such attacks remains challenging, as malicious
components use various evasion techniques. Specifically, in the case of
stealthy supply-chain attacks (SSCAs), a malicious dependency may remain
dormant until multiple conditions are met, for example, specific values of
environment variables, the version of another component, the system’s date and
time, the number of times a component has been invoked, or even random
activation. This vast space of possible conditions makes detection extremely
complex and highly unlikely.

\section*{Literature Review}
Large language models (LLMs) have been explored for security
applications~\cite{alkaraki2024exploringllmsmalwaredetection, llmvulndetection2023}, 
but they remain vulnerable when source code is
unavailable or malicious code is disguised as legitimate functionality; This project
will mitigate these risks by regenerating components to eliminate side-effectful
attacks.

Program synthesis approaches~\cite{harp:ccs:2021, feser2015synthesizing,
gulwani2011automating} use formal methods to generate programs from
specifications or examples, whereas this project will leverage LLMs for regeneration
without domain-specific constraints, allowing cross-domain scalability.

Software de-bloating~\cite{brown2024broad, babak2019less, kalhauge:2019:binary-reduction} removes unused code
to reduce attack surfaces, but this project will regenerate entire libraries from scratch,
eliminating all non-essential or potentially malicious functionality while
preserving expected behavior.

Vulnerability detection~\cite{Calzavara2015, maffeis2009language} employs
static and dynamic analysis to identify security flaws, whereas this project will bypass
detection by regenerating components into vulnerability-free versions with
equivalent functionality.

\section*{Methodology}
I propose to develop a system that eliminates SSCAs by combining program
inference, transformation, and regeneration. The key insight behind my system
is that a stealthy malicious component still exhibits the advertised component
behavior—which the system will attempt to infer and regenerate. The system will
not attempt to directly detect, remove, or interpose on vulnerable or malicious
code. It instead extracts a model of the component’s intended behavior, then
uses this model to regenerate a new, secure, vulnerability-free version of the
component. While earlier research on vulnerability elimination has demonstrated
promising results via active learning and regeneration, the techniques
underlying this system will be language- and domain-agnostic, hinting at a
potential for regenerating substantial parts of entire ecosystems.

\section*{Project Plan}

The project will be conducted over a period of 6 months, starting in February 2025 and ending in July 2025. The project will be divided into the following phases:

First, I will study
real-world examples of stealthy supply-chain attacks, such as leetlog~\cite{leetlog-attack}
and
flatmap-stream~\cite{snyk-flatmapstream-2018, ev:eurosec:2022}, to understand how attackers hide malicious behavior in software
components. 
I will review existing detection and mitigation techniques,
including static analysis methods like AST-based detection and taint analysis,
as well as dynamic analysis approaches that observe runtime behavior.
I will
also evaluate LLM-based vulnerability detection and program synthesis
techniques to assess their effectiveness. To define the scope of the system, I
will determine which programming languages to support initially, focusing on
JavaScript and Node.js, with potential expansion to Python and C++.
I will
establish metrics for correctness, such as code coverage and functional
equivalence tests, and decide which types of attacks to target.

Next, I will develop a component that extracts
the interfaces of software components and generate the necessary input-output
pairs.
I will implement a parser to extract function signatures, imports, and
global variables while resolving dependencies in multi-module projects.
I will
design LLM prompts to generate sample inputs for testing component behavior and
implement a sandboxed execution environment to safely run these inputs against
the original library. I will store successful I/O pairs and identify cases
where code execution behaves inconsistently, in order to identify the limitations of this specific approach.

Next, I will develop the next component that uses the extracted I/O pairs to
synthesize
executable code using LLM-based synthesis until the correctness threshold is
met.
To ensure functional equivalence, the system will also execute developer-provided test
suites on the regenerated code. If necessary, I will
implement an early-exit mechanism to discard libraries that contain irreducible
complexity, rely on undocumented system behaviors, or generate
non-deterministic outputs such as timestamps or randomly triggered functions.

Moving on, I will
introduce mechanisms for refinement, and parallelization.
I will develop a revision loop that continuously expands the input set to
improve coverage and iteratively refines synthesized code until correctness
conditions are satisfied.
To improve scalability, I will enable parallel processing,
allowing multiple components to be regenerated simultaneously.

Finally, I will assess the performance
and reliability of the system across multiple software components.
I will test
it on benign libraries to ensure no unintended modifications are introduced and
apply it to known malicious packages, such as flatmap-stream and leetlog, to
confirm that vulnerabilities are successfully eliminated.
I will also introduce
synthetic test cases to simulate stealthy behaviors and evaluate the system’s
effectiveness.
To benchmark its capabilities, I will compare its performance
against pure LLM-based vulnerability elimination, traditional static and
dynamic analysis tools, and search-based program synthesis techniques.

\begin{adjustbox}{max width=\textwidth}
\begin{ganttchart}[
    x unit=0.1cm, y unit chart=0.7cm,
    vgrid, hgrid,
    milestone label node/.append style={text width=4cm},
    time slot format=isodate,
    today=2025-03-18
]{2025-02-01}{2025-08-31}

  % Define months
  \gantttitlecalendar{month=name} \\

  % Literature Review
  \ganttbar[
    progress=40,
    name=litreview
  ]{Literature Review}{2025-02-01}{2025-03-28} \\

  % Define Component Behavior (Starts after Literature Review)
  \ganttbar[
    progress=50,
    name=definecomp
  ]{Define Component Behavior}{2025-03-01}{2025-03-31} \\

  % Develop Inference Component (Runs in Parallel with Regeneration)
  \ganttbar[
    progress=30,
    name=inference
  ]{Develop Inference Component}{2025-03-15}{2025-04-30} \\

  % Develop Regeneration Component (Runs in Parallel with Inference)
  \ganttbar[
    progress=10,
    name=regen
  ]{Develop Regeneration Component}{2025-03-15}{2025-05-31} \\

  % Develop Basic Prototype (Starts After Initial Progress on Inference/Regeneration)
  \ganttbar[
    progress=70,
    name=prototype
  ]{Develop Basic Prototype}{2025-04-01}{2025-05-31} \\

  % Evaluation on Simple Libraries (Extends Slightly to Overlap with Basic Prototype)
  \ganttbar[
    progress=20,
    name=evaluation
  ]{Evaluate on Simple Libraries}{2025-04-15}{2025-05-31} \\

  % Develop Complete Prototype (Includes Subtasks)
  \ganttgroup{Develop Complete Prototype}{2025-06-01}{2025-07-31} \\
  \ganttbar[
    progress=0,
    name=coverage
  ]{Implement Coverage Metrics}{2025-06-01}{2025-06-15} \\
  \ganttbar[
    progress=0,
    name=heuristics
  ]{Integrate Heuristics}{2025-06-10}{2025-06-30} \\
  \ganttbar[
    progress=0,
    name=earlyexit
  ]{Implement Early Exit Mechanism}{2025-07-01}{2025-07-15} \\

  % Expand Evaluation
  \ganttbar[
    progress=10,
    name=expand
  ]{Expand Evaluation}{2025-07-15}{2025-08-15} \\

  % Dependencies (Updated for New Tasks)
  \ganttlink{litreview}{definecomp}
  \ganttlink{definecomp}{inference}
  \ganttlink{definecomp}{regen}
  \ganttlink{inference}{prototype}
  \ganttlink{regen}{prototype}
  \ganttlink{prototype}{evaluation}
  \ganttlink{evaluation}{coverage}
  \ganttlink{evaluation}{heuristics}
  \ganttlink{evaluation}{earlyexit}
  \ganttlink{coverage}{expand}
  \ganttlink{heuristics}{expand}
  \ganttlink{earlyexit}{expand}

\end{ganttchart}
\end{adjustbox}

Throughout the project, I will be preparing the thesis text, giving weekly updates to my advisor, and meeting with my advisor bi-weekly, or as needed.

\subsection*{Expected Challenges and Open Questions}

One challenge in evaluating functional equivalence is dealing with incomplete
test coverage. If a function is only partially tested, the regenerated version
may miss critical behaviors that are not explicitly captured in the provided
input-output pairs. This can result in functionally incorrect but superficially
valid implementations. To mitigate this, I will explore the use of fuzz testing
to generate additional inputs, ensuring that the regenerated component is
exercised across a wider range of possible behaviors. By leveraging automated
input generation techniques, I aim to improve test coverage and reduce the
likelihood of missing important edge cases.

Another challenge lies in scaling beyond JavaScript and Node.js to support
additional languages such as Python, Rust, or C++. Each language presents
unique challenges when it comes to actually interacting with it.
To address this, I will modularize the input-generation
logic, allowing for language-specific extensions. This will enable
adaptation to different programming languages while maintaining a consistent
approach to program inference and regeneration across multiple ecosystems.

\subsection*{Resources}

The primary resources required for this project are as follows:

\begin{enumerate}
    \item Access to the OpenAI API to use as the LLM backend.
    \item Access to an open-source model API to use as an alternative LLM backend.
    \item Access to open source library repositories such as npm, PyPI, and crates.io.
\end{enumerate}

\section*{Expected Outcomes}
By the end of the project, I will have built a system that will produce as
output either a vulnerability-free version of a software component it takes as
input or a message that it cannot operate on its input component, because the
component falls outside its regeneration scope.

The deliverables for this project will include the following:

\begin{itemize}
  \item	CLI Tool: A fully functional command-line tool for regenerating dependencies.
	\item	Benchmarking Report: A detailed evaluation of the system's effectiveness across real-world packages.
	\item	Open Source Release: Release as an MIT-licensed project on GitHub.
\end{itemize}



\printbibliography[heading=bibintoc,title={Bibliography}]
\input{backmatter/backpage.tex}

\end{document}
